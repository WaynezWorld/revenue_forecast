{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a6fde-bdb3-46c7-8a32-f73e3a3aba04",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "parameters"
   },
   "outputs": [],
   "source": [
    "# === PARAMETERS ===\n",
    "RUN_ID = None  # set to a specific run_id string if you want; otherwise we'll auto-pick latest SUCCEEDED\n",
    "ASOF_SCOPE = \"GLOBAL__WAPE_MICRO_OVERALL\"\n",
    "OVERRIDE_SCOPE = \"PC_REASON__WAPE_MICRO_OVERALL__OVERRIDE5PCT\"\n",
    "EPS = 100.0\n",
    "MAX_HORIZON = 12\n",
    "EVAL_ANCHORS = 12               # last 12 anchors (months) to backtest\n",
    "OVERRIDE_MIN_REL_IMPROV = 0.05  # 5%\n",
    "MAPE_EPSILON = 100              # per your decision\n",
    "BIAS_MAX_ABS = 0.02             # 2% guardrail (tunable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "latest"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "\n",
    "# Snowflake notebook usually provides `session`\n",
    "if RUN_ID is None:\n",
    "    df = session.sql(\"\"\"\n",
    "      select run_id\n",
    "      from DB_BI_P_SANDBOX.SANDBOX.FORECAST_RUNS\n",
    "      where status = 'SUCCEEDED'\n",
    "      order by triggered_at desc\n",
    "      limit 1\n",
    "    \"\"\").to_pandas()\n",
    "    RUN_ID = df.iloc[0][\"RUN_ID\"]\n",
    "\n",
    "asof = session.sql(f\"\"\"\n",
    "  select asof_fiscal_yyyymm\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_RUNS\n",
    "  where run_id = '{RUN_ID}'\n",
    "\"\"\").to_pandas().iloc[0][\"ASOF_FISCAL_YYYYMM\"]\n",
    "\n",
    "print(\"RUN_ID:\", RUN_ID)\n",
    "print(\"ASOF:\", asof)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "experiment_row_register_models"
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = \"EXP_GLOBAL_3A_V1\"\n",
    "now = datetime.utcnow()\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "merge into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_EXPERIMENTS t\n",
    "using (select '{EXPERIMENT_ID}' experiment_id) s\n",
    "on t.experiment_id = s.experiment_id\n",
    "when not matched then insert (experiment_id, experiment_name, experiment_desc, created_by, created_at, tags)\n",
    "values (\n",
    "  '{EXPERIMENT_ID}',\n",
    "  'Global candidates + per-series overrides (3A)',\n",
    "  'Train global candidate models; choose global champion + per-series overrides by WAPE improvement.',\n",
    "  current_user(), current_timestamp(),\n",
    "  parse_json('{{\"type\":\"3A\",\"mape_epsilon\":{MAPE_EPSILON},\"override_min_rel_improv\":{OVERRIDE_MIN_REL_IMPROV}}}')\n",
    ");\n",
    "\"\"\").collect()\n",
    "\n",
    "def new_model_run_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "# --- Model candidates (updated: removed Ridge) ---\n",
    "# See METRIC_AUDIT_REPORT.md for analysis - Ridge incompatible with signed_log1p transform\n",
    "CANDIDATES = [\n",
    "    # baseline: seasonal naive (computed in SQL; no sklearn needed)\n",
    "    {\"name\": \"SEASONAL_NAIVE_LAG12\", \"family\": \"baseline\",\n",
    "     \"params\": {\"kind\": \"seasonal_naive_lag12\"}},\n",
    "    \n",
    "    # ❌ REMOVED: Ridge regression - incompatible with exponential inverse transform\n",
    "    # Linear models extrapolate wildly in log-space, producing 1130% WAPE failure\n",
    "    # See METRIC_AUDIT_REPORT.md and docs/MODEL_TRANSFORM_GUIDE.md\n",
    "    \n",
    "    # gradient boosting (sklearn) - tree-based models are bounded, work well with log transforms\n",
    "    {\"name\": \"GBR_OHE\", \"family\": \"gbr\", \"params\": {\"target_transform\": \"signed_log1p\"}},\n",
    "]\n",
    "# --- end candidates ---\n",
    "\n",
    "model_runs = []\n",
    "for c in CANDIDATES:\n",
    "    mrid = new_model_run_id()\n",
    "    model_runs.append((c, mrid))\n",
    "    session.sql(f\"\"\"\n",
    "      insert into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\n",
    "      (model_run_id, run_id, asof_fiscal_yyyymm, experiment_id, model_scope, model_family, feature_set_id,\n",
    "       target_name, max_horizon, params, training_env, status, started_at, updated_at)\n",
    "      select\n",
    "        '{mrid}', '{RUN_ID}', {asof}, '{EXPERIMENT_ID}', 'GLOBAL',\n",
    "        '{c[\"family\"]}', 'OHE_V1',\n",
    "        'TOTAL_REVENUE', {MAX_HORIZON},\n",
    "        parse_json('{json.dumps(c[\"params\"])}'),\n",
    "        object_construct('python_version', '{sys.version}', 'sklearn_version', '{sklearn.__version__}'),\n",
    "        'PENDING', current_timestamp(), current_timestamp()\n",
    "    \"\"\").collect()\n",
    "\n",
    "print(f\"Registered {len(CANDIDATES)} model runs:\")\n",
    "for (c, mrid) in model_runs:\n",
    "    print(f\"  {c['name']:30s} → {mrid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0408d0c8-563c-43be-b8d0-e6dd930d10dd",
   "metadata": {
    "language": "python",
    "name": "load_snap_features"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "ds = session.sql(f\"\"\"\n",
    "  select *\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_DATASET_PC_REASON_H_SNAP\n",
    "  where run_id = '{RUN_ID}'\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "# ---- Column map (case-safe) ----\n",
    "lower_cols = {c.lower(): c for c in ds.columns}\n",
    "\n",
    "# ---- Required ID columns (use actual column names from the table) ----\n",
    "required = [\n",
    "    \"roll_up_shop\",\n",
    "    \"reason_group\",\n",
    "    \"anchor_fiscal_yyyymm\",\n",
    "    \"anchor_month_seq\",\n",
    "    \"target_fiscal_yyyymm\",\n",
    "    \"target_month_seq\",\n",
    "    \"horizon\",\n",
    "    \"run_id\",\n",
    "]\n",
    "missing = [c for c in required if c not in lower_cols]\n",
    "if missing:\n",
    "    raise ValueError(f\"Dataset snap missing required columns: {missing}\")\n",
    "\n",
    "id_cols = [lower_cols[c] for c in required]\n",
    "\n",
    "# ---- Target column (explicit) ----\n",
    "y_col = \"Y_REVENUE\"\n",
    "if y_col not in ds.columns:\n",
    "    raise ValueError(f\"Target column '{y_col}' not found. Available columns: {ds.columns.tolist()}\")\n",
    "\n",
    "print(\"Using y_col:\", y_col)\n",
    "print(\"ID cols:\", id_cols)\n",
    "\n",
    "# ---- Feature selection ----\n",
    "# Exclude IDs + target. Also exclude bookkeeping columns you don't want as model inputs.\n",
    "exclude_cols = set(id_cols + [y_col, \"BUILT_AT\", \"ROW_HASH\"])\n",
    "\n",
    "# Optional: exclude BUDGET_TARGET from features to prevent \"cheating\" during backtest\n",
    "# if budget is not truly known at prediction time in your process. If budget is always known, remove this line.\n",
    "# exclude_cols.add(\"BUDGET_TARGET\")\n",
    "\n",
    "feature_cols = [c for c in ds.columns if c not in exclude_cols]\n",
    "\n",
    "# Split categorical vs numeric\n",
    "cat_cols = [c for c in feature_cols if ds[c].dtype == \"object\"]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "# Ensure series identifiers are included as categorical features for GLOBAL models\n",
    "for c in [\"ROLL_UP_SHOP\", \"REASON_GROUP\"]:\n",
    "    if c in ds.columns and c not in cat_cols:\n",
    "        cat_cols.append(c)\n",
    "        if c in num_cols:\n",
    "            num_cols.remove(c)\n",
    "\n",
    "print(\"Numeric features:\", len(num_cols))\n",
    "print(\"Categorical features:\", len(cat_cols))\n",
    "print(\"Example numeric cols:\", num_cols[:10])\n",
    "print(\"Example categorical cols:\", cat_cols[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ca3b5-e662-4474-b25f-d497922ae7f4",
   "metadata": {
    "language": "python",
    "name": "add_horizon_feature"
   },
   "outputs": [],
   "source": [
    "# Add HORIZON as a numeric feature (we want one global model across horizons)\n",
    "if \"HORIZON\" not in num_cols:\n",
    "    num_cols.append(\"HORIZON\")\n",
    "\n",
    "# Fill nulls defensively\n",
    "ds[num_cols] = ds[num_cols].fillna(0)\n",
    "ds[cat_cols] = ds[cat_cols].fillna(\"UNKNOWN\")\n",
    "\n",
    "print(\"Numeric features (post):\", len(num_cols))\n",
    "print(\"Categorical features (post):\", len(cat_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef96b19-f7ee-4f2c-81b9-a4ecdca1036e",
   "metadata": {
    "language": "python",
    "name": "log_helpers_model_factory"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def signed_log1p(x, eps: float):\n",
    "    \"\"\"\n",
    "    Signed log transform:\n",
    "      y = sign(x) * log1p(|x| / eps)\n",
    "\n",
    "    eps > 0 controls how aggressive the compression is.\n",
    "    \"\"\"\n",
    "    if eps is None or eps <= 0:\n",
    "        raise ValueError(\"eps must be > 0\")\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return np.sign(x) * np.log1p(np.abs(x) / eps)\n",
    "\n",
    "def signed_expm1(y, eps: float):\n",
    "    \"\"\"\n",
    "    Inverse of signed_log1p:\n",
    "      x = sign(y) * eps * (expm1(|y|))\n",
    "    \"\"\"\n",
    "    if eps is None or eps <= 0:\n",
    "        raise ValueError(\"eps must be > 0\")\n",
    "\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    return np.sign(y) * eps * np.expm1(np.abs(y))\n",
    "\n",
    "def signed_log10_1p(x, eps: float):\n",
    "    \"\"\"\n",
    "    Optional (not used yet): signed log10 variant.\n",
    "      y = sign(x) * log10(1 + |x|/eps)\n",
    "    \"\"\"\n",
    "    if eps is None or eps <= 0:\n",
    "        raise ValueError(\"eps must be > 0\")\n",
    "\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return np.sign(x) * np.log10(1.0 + (np.abs(x) / eps))\n",
    "\n",
    "def signed_pow10_m1(y, eps: float):\n",
    "    \"\"\"\n",
    "    Inverse of signed_log10_1p:\n",
    "      x = sign(y) * eps * ((10^|y|) - 1)\n",
    "    \"\"\"\n",
    "    if eps is None or eps <= 0:\n",
    "        raise ValueError(\"eps must be > 0\")\n",
    "\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    return np.sign(y) * eps * (np.power(10.0, np.abs(y)) - 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdeaeec-ace1-426b-84a4-dad354473fc9",
   "metadata": {
    "language": "python",
    "name": "resolve_anchors_clear_prior_preds"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "anchor_seq_col = \"ANCHOR_MONTH_SEQ\"\n",
    "target_seq_col = \"TARGET_MONTH_SEQ\"\n",
    "pc_col = \"ROLL_UP_SHOP\"\n",
    "rg_col = \"REASON_GROUP\"\n",
    "h_col = \"HORIZON\"\n",
    "\n",
    "y_col = \"Y_REVENUE\"  # explicit\n",
    "\n",
    "anchors = sorted(ds[anchor_seq_col].unique())\n",
    "eval_anchors = anchors[-EVAL_ANCHORS:]  # last 12 anchors\n",
    "\n",
    "print(\"Anchors min/max:\", min(anchors), max(anchors))\n",
    "print(\"Eval anchors:\", eval_anchors)\n",
    "\n",
    "# Identify model_run_ids from earlier registration cell\n",
    "MODEL_RUN_IDS = [mrid for (_, mrid) in model_runs]\n",
    "print(\"MODEL_RUN_IDS:\", MODEL_RUN_IDS)\n",
    "\n",
    "# Clear prior predictions for these model_run_ids (rerunnable)\n",
    "mrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n",
    "session.sql(f\"\"\"\n",
    "delete from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "where model_run_id in ({mrid_list_sql});\n",
    "\"\"\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfbde6a-3662-4ada-8cdb-77a93aad5ed8",
   "metadata": {
    "language": "python",
    "name": "backtest_RIDGE_GBR"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pred_rows = []\n",
    "now = datetime.utcnow()\n",
    "\n",
    "# ---- Ensure eval_anchors are plain ints (avoid np.int8 etc) ----\n",
    "eval_anchors = [int(x) for x in eval_anchors]\n",
    "\n",
    "# ---- Ensure model_runs exists (don’t rely on hidden state) ----\n",
    "# Expected upstream vars (depending on your notebook):\n",
    "# - candidates: list[dict] with {\"name\": ...}\n",
    "# - model_run_ids: dict mapping name -> uuid\n",
    "if \"model_runs\" not in globals() or model_runs is None:\n",
    "    if \"candidates\" in globals() and \"model_run_ids\" in globals():\n",
    "        model_runs = [(c, model_run_ids[c[\"name\"]]) for c in candidates if c.get(\"name\") in model_run_ids]\n",
    "    elif \"CANDIDATES\" in globals() and \"model_run_ids\" in globals():\n",
    "        model_runs = [(c, model_run_ids[c[\"name\"]]) for c in CANDIDATES if c.get(\"name\") in model_run_ids]\n",
    "    else:\n",
    "        raise NameError(\n",
    "            \"model_runs is not defined and could not be inferred. \"\n",
    "            \"Define `model_runs = [(candidate_dict, model_run_id), ...]` in experiment_row_register_models.\"\n",
    "        )\n",
    "\n",
    "# Also keep a convenience list for later leaderboard cells\n",
    "MODEL_RUN_IDS = [mrid for _, mrid in model_runs]\n",
    "\n",
    "# Optional: only used if you want to prevent huge Ridge blowups in transformed space.\n",
    "RIDGE_SLOG_CLIP_MARGIN = 0.25\n",
    "\n",
    "for (cand, mrid) in model_runs:\n",
    "    cname = cand[\"name\"]\n",
    "    if cname == \"SEASONAL_NAIVE_LAG12\":\n",
    "        continue  # baseline handled in SQL\n",
    "\n",
    "    pipe = make_model(cname)\n",
    "\n",
    "    for a in eval_anchors:\n",
    "        # Train on rows whose targets would have been known at anchor a:\n",
    "        train = ds[(ds[target_seq_col] <= a)].copy()\n",
    "        test  = ds[(ds[anchor_seq_col] == a)].copy()\n",
    "\n",
    "        # drop null targets defensively\n",
    "        train = train[train[y_col].notna()]\n",
    "        test  = test[test[y_col].notna()]\n",
    "\n",
    "        if train.empty or test.empty:\n",
    "            continue\n",
    "\n",
    "        X_train = train[num_cols + cat_cols]\n",
    "        X_test  = test[num_cols + cat_cols]\n",
    "\n",
    "        y_train = train[y_col].astype(float).to_numpy()\n",
    "\n",
    "        # ---- Transform with explicit EPS from parameters ----\n",
    "        y_train_t = signed_log1p(y_train, eps=EPS)\n",
    "\n",
    "        # Optional guard: clip for Ridge only (helps prevent extreme extrapolation)\n",
    "        if cname.upper().startswith(\"RIDGE\"):\n",
    "            lo = np.nanmin(y_train_t) - RIDGE_SLOG_CLIP_MARGIN\n",
    "            hi = np.nanmax(y_train_t) + RIDGE_SLOG_CLIP_MARGIN\n",
    "\n",
    "        pipe.fit(X_train, y_train_t)\n",
    "        yhat_t = pipe.predict(X_test)\n",
    "\n",
    "        if cname.upper().startswith(\"RIDGE\"):\n",
    "            yhat_t = np.clip(yhat_t, lo, hi)\n",
    "\n",
    "        yhat = signed_expm1(yhat_t, eps=EPS)\n",
    "\n",
    "        # Append row-wise predictions for Snowflake table\n",
    "        for j, (_, r) in enumerate(test.iterrows()):\n",
    "            pred_rows.append({\n",
    "                \"MODEL_RUN_ID\": mrid,\n",
    "                \"ROLL_UP_SHOP\": str(r[pc_col]),\n",
    "                \"REASON_GROUP\": str(r[rg_col]),\n",
    "                \"ANCHOR_FISCAL_YYYYMM\": int(r[\"ANCHOR_FISCAL_YYYYMM\"]),\n",
    "                \"ANCHOR_MONTH_SEQ\": int(r[anchor_seq_col]),\n",
    "                \"HORIZON\": int(r[h_col]),\n",
    "                \"TARGET_FISCAL_YYYYMM\": int(r[\"TARGET_FISCAL_YYYYMM\"]),\n",
    "                \"TARGET_MONTH_SEQ\": int(r[target_seq_col]),\n",
    "                \"Y_TRUE\": float(r[y_col]),\n",
    "                \"Y_PRED\": float(yhat[j]),\n",
    "                \"Y_PRED_LO\": None,\n",
    "                \"Y_PRED_HI\": None,\n",
    "                \"CREATED_AT\": now,\n",
    "                \"DETAILS\": {\"eps\": float(EPS), \"candidate\": cname, \"eval_anchor\": int(a)}\n",
    "            })\n",
    "\n",
    "pred_df = pd.DataFrame(pred_rows)\n",
    "print(\"Python prediction rows:\", len(pred_df))\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aeb222-90a2-4334-9371-2bfdc883b41f",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "print(\"EPS:\", EPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b788b-a0cf-4c92-8d6c-560f6b85caf2",
   "metadata": {
    "language": "python",
    "name": "write_to_sql"
   },
   "outputs": [],
   "source": [
    "if len(pred_df) > 0:\n",
    "    session.write_pandas(\n",
    "        pred_df,\n",
    "        table_name=\"FORECAST_MODEL_BACKTEST_PREDICTIONS\",\n",
    "        database=\"DB_BI_P_SANDBOX\",\n",
    "        schema=\"SANDBOX\",\n",
    "        auto_create_table=False,\n",
    "        overwrite=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78d20d4-caf0-4298-9347-45451a900e04",
   "metadata": {
    "language": "python",
    "name": "get_columns"
   },
   "outputs": [],
   "source": [
    "# Detect column names in FORECAST_ACTUALS_PC_REASON_MTH_SNAP (no guessing)\n",
    "cols = session.sql(\"\"\"\n",
    "select column_name\n",
    "from DB_BI_P_SANDBOX.INFORMATION_SCHEMA.COLUMNS\n",
    "where table_schema = 'SANDBOX'\n",
    "  and table_name   = 'FORECAST_ACTUALS_PC_REASON_MTH_SNAP'\n",
    "order by ordinal_position\n",
    "\"\"\").to_pandas()[\"COLUMN_NAME\"].tolist()\n",
    "\n",
    "print(\"ACTUALS_SNAP columns:\", cols)\n",
    "\n",
    "# Find the month sequence column\n",
    "if \"MONTH_SEQ\" in cols:\n",
    "    actuals_seq_col = \"MONTH_SEQ\"\n",
    "else:\n",
    "    raise ValueError(\"Could not find MONTH_SEQ in FORECAST_ACTUALS_PC_REASON_MTH_SNAP. Paste the column list above.\")\n",
    "\n",
    "# Find the revenue/actual value column (ordered candidates)\n",
    "actual_candidates = [\n",
    "    \"REVENUE\", \"ACTUAL_REVENUE\", \"Y_REVENUE\", \"TOTAL_REVENUE\",\n",
    "    \"REVENUE_MTH\", \"ACTUALS_REVENUE\", \"ACTUAL\"\n",
    "]\n",
    "actuals_y_col = next((c for c in actual_candidates if c in cols), None)\n",
    "\n",
    "if actuals_y_col is None:\n",
    "    raise ValueError(\n",
    "        \"Could not find an actuals revenue column in FORECAST_ACTUALS_PC_REASON_MTH_SNAP. \"\n",
    "        f\"Columns are: {cols}\"\n",
    "    )\n",
    "\n",
    "print(\"Using actuals_seq_col:\", actuals_seq_col)\n",
    "print(\"Using actuals_y_col:\", actuals_y_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7e1b15-52b0-4712-a7cd-046b7ff187a1",
   "metadata": {
    "language": "python",
    "name": "baseline_seasonal_naive"
   },
   "outputs": [],
   "source": [
    "baseline_mrid = [mrid for (c, mrid) in model_runs if c[\"name\"] == \"SEASONAL_NAIVE_LAG12\"][0]\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "insert into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "(model_run_id, roll_up_shop, reason_group,\n",
    " anchor_fiscal_yyyymm, anchor_month_seq, horizon,\n",
    " target_fiscal_yyyymm, target_month_seq,\n",
    " y_true, y_pred, y_pred_lo, y_pred_hi,\n",
    " created_at, details)\n",
    "with ds as (\n",
    "  select *\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_DATASET_PC_REASON_H_SNAP\n",
    "  where run_id = '{RUN_ID}'\n",
    "),\n",
    "eval_anchors as (\n",
    "  select distinct ds.anchor_month_seq as anchor_month_seq\n",
    "  from ds\n",
    "  qualify dense_rank() over (order by ds.anchor_month_seq desc) <= {EVAL_ANCHORS}\n",
    "),\n",
    "base as (\n",
    "  select\n",
    "    ds.roll_up_shop,\n",
    "    ds.reason_group,\n",
    "    ds.anchor_fiscal_yyyymm,\n",
    "    ds.anchor_month_seq,\n",
    "    ds.horizon,\n",
    "    ds.target_fiscal_yyyymm,\n",
    "    ds.target_month_seq,\n",
    "    ds.y_revenue::number as y_true\n",
    "  from ds\n",
    "  join eval_anchors ea\n",
    "    on ea.anchor_month_seq = ds.anchor_month_seq\n",
    "),\n",
    "lag12 as (\n",
    "  select\n",
    "    a.roll_up_shop,\n",
    "    a.reason_group,\n",
    "    a.{actuals_seq_col} as month_seq,\n",
    "    a.{actuals_y_col}   as y_lag12\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_ACTUALS_PC_REASON_MTH_SNAP a\n",
    "  where a.run_id = '{RUN_ID}'\n",
    ")\n",
    "select\n",
    "  '{baseline_mrid}',\n",
    "  b.roll_up_shop, b.reason_group,\n",
    "  b.anchor_fiscal_yyyymm, b.anchor_month_seq, b.horizon,\n",
    "  b.target_fiscal_yyyymm, b.target_month_seq,\n",
    "  b.y_true,\n",
    "  l.y_lag12 as y_pred,\n",
    "  null, null,\n",
    "  current_timestamp(),\n",
    "  parse_json('{{\"baseline\":\"seasonal_naive_lag12\"}}')\n",
    "from base b\n",
    "left join lag12 l\n",
    "  on l.roll_up_shop = b.roll_up_shop\n",
    " and l.reason_group = b.reason_group\n",
    " and l.month_seq = (b.target_month_seq - 12);\n",
    "\"\"\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a725d6b-a6ac-4bcb-8a6b-86b738921cbe",
   "metadata": {
    "language": "python",
    "name": "validate_prediction_coverage"
   },
   "outputs": [],
   "source": [
    "# Show how many backtest predictions we have per model_run_id\n",
    "mrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "select\n",
    "  model_run_id,\n",
    "  count(*) as rows_pred,\n",
    "  count_if(y_pred is null) as null_preds,\n",
    "  count_if(y_true is null) as null_true,\n",
    "  min(anchor_month_seq) as min_anchor_seq,\n",
    "  max(anchor_month_seq) as max_anchor_seq,\n",
    "  min(horizon) as min_h,\n",
    "  max(horizon) as max_h\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "where model_run_id in ({mrid_list_sql})\n",
    "group by 1\n",
    "order by 1\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102f555-6b4c-406d-8095-2967844a103d",
   "metadata": {
    "language": "python",
    "name": "horizon_coverage"
   },
   "outputs": [],
   "source": [
    "# Horizon coverage by anchor for ONE model_run_id (pick any; they should match)\n",
    "one_mrid = MODEL_RUN_IDS[0]\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "select\n",
    "  anchor_month_seq,\n",
    "  count(*) as rowz,\n",
    "  count(distinct horizon) as horizons_present,\n",
    "  min(horizon) as min_h,\n",
    "  max(horizon) as max_h,\n",
    "  min(target_month_seq) as min_target_seq,\n",
    "  max(target_month_seq) as max_target_seq\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "where model_run_id = '{one_mrid}'\n",
    "group by 1\n",
    "order by 1\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec5246-b359-4b20-868f-bc7d9730e922",
   "metadata": {
    "language": "python",
    "name": "fixed_grid"
   },
   "outputs": [],
   "source": [
    "one_mrid = session.sql(f\"\"\"\n",
    "  select model_run_id\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\n",
    "  where run_id = '{RUN_ID}'\n",
    "  order by started_at desc\n",
    "  limit 1\n",
    "\"\"\").to_pandas().iloc[0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f780cda-762f-41e7-8afb-51e5051fdea6",
   "metadata": {
    "language": "python",
    "name": "compute_metrics"
   },
   "outputs": [],
   "source": [
    "# --- Inputs ---\n",
    "fixed_eval_anchors = [48]\n",
    "anchor_list_sql = \", \".join([str(x) for x in fixed_eval_anchors])\n",
    "anchor_array_sql = \"array_construct(\" + \", \".join([str(x) for x in fixed_eval_anchors]) + \")\"\n",
    "\n",
    "mrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n",
    "\n",
    "baseline_mrid = [mrid for (c, mrid) in model_runs if c[\"name\"] == \"SEASONAL_NAIVE_LAG12\"][0]\n",
    "\n",
    "# --- Clear existing metrics for reruns ---\n",
    "session.sql(f\"\"\"\n",
    "delete from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS\n",
    "where model_run_id in ({mrid_list_sql})\n",
    "\"\"\").collect()\n",
    "\n",
    "# --- Compute + insert metrics (note: INSERT ... WITH ... SELECT ...) ---\n",
    "session.sql(f\"\"\"\n",
    "insert into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS\n",
    "(model_run_id, metric_scope, metric_name, horizon, value, computed_at, details)\n",
    "\n",
    "with p as (\n",
    "  select *\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "  where model_run_id in ({mrid_list_sql})\n",
    "    and anchor_month_seq in ({anchor_list_sql})\n",
    "),\n",
    "naive as (\n",
    "  select\n",
    "    roll_up_shop,\n",
    "    reason_group,\n",
    "    anchor_month_seq,\n",
    "    horizon,\n",
    "    abs(y_true - y_pred) as abs_naive_err\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "  where model_run_id = '{baseline_mrid}'\n",
    "    and anchor_month_seq in ({anchor_list_sql})\n",
    "),\n",
    "p3 as (\n",
    "  select\n",
    "    p.*,\n",
    "    (p.y_true - p.y_pred) as err,\n",
    "    (p.y_pred - p.y_true) as err_signed,\n",
    "    abs(p.y_true - p.y_pred) as abs_err,\n",
    "    abs(p.y_true) as abs_y,\n",
    "    n.abs_naive_err\n",
    "  from p\n",
    "  left join naive n\n",
    "    on n.roll_up_shop = p.roll_up_shop\n",
    "   and n.reason_group = p.reason_group\n",
    "   and n.anchor_month_seq = p.anchor_month_seq\n",
    "   and n.horizon = p.horizon\n",
    "),\n",
    "\n",
    "-- MICRO\n",
    "micro_overall as (\n",
    "  select\n",
    "    model_run_id,\n",
    "    'OVERALL' as metric_scope,\n",
    "    null::number as horizon,\n",
    "    avg(abs_err) as mae,\n",
    "    sqrt(avg(err*err)) as rmse,\n",
    "    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n",
    "    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n",
    "    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n",
    "    sum(err_signed) / nullif(sum(abs_y),0) as bias\n",
    "  from p3\n",
    "  group by 1\n",
    "),\n",
    "micro_by_h as (\n",
    "  select\n",
    "    model_run_id,\n",
    "    'BY_HORIZON' as metric_scope,\n",
    "    horizon,\n",
    "    avg(abs_err) as mae,\n",
    "    sqrt(avg(err*err)) as rmse,\n",
    "    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n",
    "    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n",
    "    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n",
    "    sum(err_signed) / nullif(sum(abs_y),0) as bias\n",
    "  from p3\n",
    "  group by 1,3\n",
    "),\n",
    "\n",
    "-- MACRO (per series, then average)\n",
    "series_overall as (\n",
    "  select\n",
    "    model_run_id,\n",
    "    roll_up_shop,\n",
    "    reason_group,\n",
    "    'OVERALL' as metric_scope,\n",
    "    null::number as horizon,\n",
    "    avg(abs_err) as mae,\n",
    "    sqrt(avg(err*err)) as rmse,\n",
    "    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n",
    "    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n",
    "    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n",
    "    sum(err_signed) / nullif(sum(abs_y),0) as bias\n",
    "  from p3\n",
    "  group by 1,2,3\n",
    "),\n",
    "series_by_h as (\n",
    "  select\n",
    "    model_run_id,\n",
    "    roll_up_shop,\n",
    "    reason_group,\n",
    "    'BY_HORIZON' as metric_scope,\n",
    "    horizon,\n",
    "    avg(abs_err) as mae,\n",
    "    sqrt(avg(err*err)) as rmse,\n",
    "    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n",
    "    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n",
    "    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n",
    "    sum(err_signed) / nullif(sum(abs_y),0) as bias\n",
    "  from p3\n",
    "  group by 1,2,3,5\n",
    "),\n",
    "macro_agg as (\n",
    "  select\n",
    "    model_run_id,\n",
    "    metric_scope,\n",
    "    horizon,\n",
    "    avg(mae) as mae,\n",
    "    avg(rmse) as rmse,\n",
    "    avg(wape) as wape,\n",
    "    avg(mape_eps) as mape_eps,\n",
    "    avg(mase) as mase,\n",
    "    avg(bias) as bias\n",
    "  from (\n",
    "    select model_run_id, metric_scope, horizon, mae, rmse, wape, mape_eps, mase, bias from series_overall\n",
    "    union all\n",
    "    select model_run_id, metric_scope, horizon, mae, rmse, wape, mape_eps, mase, bias from series_by_h\n",
    "  )\n",
    "  group by 1,2,3\n",
    ")\n",
    "\n",
    "-- Emit rows into FORECAST_MODEL_METRICS\n",
    "select\n",
    "  model_run_id,\n",
    "  metric_scope,\n",
    "  metric_name,\n",
    "  horizon,\n",
    "  value,\n",
    "  current_timestamp(),\n",
    "  object_construct('series_agg','MICRO','eval_anchors',{anchor_array_sql},'mape_epsilon',{MAPE_EPSILON})\n",
    "from (\n",
    "  select model_run_id, metric_scope, horizon, 'MAE' as metric_name, mae as value from micro_overall\n",
    "  union all select model_run_id, metric_scope, horizon, 'RMSE', rmse from micro_overall\n",
    "  union all select model_run_id, metric_scope, horizon, 'WAPE', wape from micro_overall\n",
    "  union all select model_run_id, metric_scope, horizon, 'MAPE_EPS', mape_eps from micro_overall\n",
    "  union all select model_run_id, metric_scope, horizon, 'MASE', mase from micro_overall\n",
    "  union all select model_run_id, metric_scope, horizon, 'BIAS', bias from micro_overall\n",
    "\n",
    "  union all select model_run_id, metric_scope, horizon, 'MAE', mae from micro_by_h\n",
    "  union all select model_run_id, metric_scope, horizon, 'RMSE', rmse from micro_by_h\n",
    "  union all select model_run_id, metric_scope, horizon, 'WAPE', wape from micro_by_h\n",
    "  union all select model_run_id, metric_scope, horizon, 'MAPE_EPS', mape_eps from micro_by_h\n",
    "  union all select model_run_id, metric_scope, horizon, 'MASE', mase from micro_by_h\n",
    "  union all select model_run_id, metric_scope, horizon, 'BIAS', bias from micro_by_h\n",
    ")\n",
    "\n",
    "union all\n",
    "\n",
    "select\n",
    "  model_run_id,\n",
    "  metric_scope,\n",
    "  metric_name,\n",
    "  horizon,\n",
    "  value,\n",
    "  current_timestamp(),\n",
    "  object_construct('series_agg','MACRO','eval_anchors',{anchor_array_sql},'mape_epsilon',{MAPE_EPSILON})\n",
    "from (\n",
    "  select model_run_id, metric_scope, horizon, 'MAE' as metric_name, mae as value from macro_agg\n",
    "  union all select model_run_id, metric_scope, horizon, 'RMSE', rmse from macro_agg\n",
    "  union all select model_run_id, metric_scope, horizon, 'WAPE', wape from macro_agg\n",
    "  union all select model_run_id, metric_scope, horizon, 'MAPE_EPS', mape_eps from macro_agg\n",
    "  union all select model_run_id, metric_scope, horizon, 'MASE', mase from macro_agg\n",
    "  union all select model_run_id, metric_scope, horizon, 'BIAS', bias from macro_agg\n",
    ")\n",
    "\"\"\").collect()\n",
    "\n",
    "print(\"Cell 11 done. Anchors:\", fixed_eval_anchors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccca2d9-28e3-4056-85be-eb37fb631dd8",
   "metadata": {
    "language": "python",
    "name": "leaderboard"
   },
   "outputs": [],
   "source": [
    "# --- leaderboard (replace entire cell) ---\n",
    "mrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "with s as (\n",
    "  select\n",
    "    m.model_run_id,\n",
    "    r.params:\"candidate\"::string as candidate,\n",
    "    m.value as wape_micro_overall,\n",
    "    r.updated_at\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS m\n",
    "  join DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS r\n",
    "    on r.model_run_id = m.model_run_id\n",
    "  where m.model_run_id in ({mrid_list_sql})\n",
    "    and m.metric_scope = 'OVERALL'\n",
    "    and m.metric_name  = 'WAPE'\n",
    "    and m.details:\"series_agg\"::string = 'MICRO'\n",
    "),\n",
    "best as (\n",
    "  select *\n",
    "  from s\n",
    "  qualify row_number() over (\n",
    "    partition by candidate\n",
    "    order by wape_micro_overall asc, updated_at desc\n",
    "  ) = 1\n",
    ")\n",
    "select model_run_id, candidate, wape_micro_overall\n",
    "from best\n",
    "order by wape_micro_overall\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2765635c-f297-47f8-b86a-ba72a545d361",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "select\n",
    "  params:\"candidate\"::string as candidate,\n",
    "  model_run_id,\n",
    "  created_at\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\n",
    "where run_id = '6673357e-8195-4146-9e36-17209b6cca57'\n",
    "  and params:\"candidate\"::string = 'RIDGE_OHE'\n",
    "order by created_at;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d07a9-dc56-409c-9247-a0a0355e2bb5",
   "metadata": {
    "language": "python",
    "name": "persist_champion"
   },
   "outputs": [],
   "source": [
    "# --- Inputs you already have ---\n",
    "# RUN_ID, MODEL_RUN_IDS, MAPE_EPSILON, fixed_eval_anchors\n",
    "fixed_eval_anchors = [48]\n",
    "anchor_array_sql = \"array_construct(\" + \", \".join([str(x) for x in fixed_eval_anchors]) + \")\"\n",
    "\n",
    "# 1) Get ASOF_FISCAL_YYYYMM for this RUN_ID\n",
    "asof = session.sql(f\"\"\"\n",
    "select asof_fiscal_yyyymm\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_RUNS\n",
    "where run_id = '{RUN_ID}'\n",
    "\"\"\").to_pandas().iloc[0][\"ASOF_FISCAL_YYYYMM\"]\n",
    "\n",
    "# 2) Pick champion by WAPE / MICRO / OVERALL (fixed-grid anchors already embedded in metrics.details)\n",
    "champ = session.sql(f\"\"\"\n",
    "with scores as (\n",
    "  select\n",
    "    m.model_run_id,\n",
    "    r.params:\"candidate\"::string as candidate,\n",
    "    m.value as wape_micro_overall\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS m\n",
    "  join DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS r\n",
    "    on r.model_run_id = m.model_run_id\n",
    "  where r.run_id = '{RUN_ID}'\n",
    "    and m.metric_scope = 'OVERALL'\n",
    "    and m.metric_name = 'WAPE'\n",
    "    and m.details:\"series_agg\"::string = 'MICRO'\n",
    "  order by wape_micro_overall\n",
    ")\n",
    "select * from scores limit 1\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "champ_mrid = champ.iloc[0][\"MODEL_RUN_ID\"]\n",
    "champ_candidate = champ.iloc[0][\"CANDIDATE\"]\n",
    "champ_wape = float(champ.iloc[0][\"WAPE_MICRO_OVERALL\"])\n",
    "\n",
    "print(\"Champion:\", champ_candidate, champ_mrid, \"WAPE=\", champ_wape, \"ASOF=\", asof)\n",
    "\n",
    "# 3) Upsert into FORECAST_MODEL_CHAMPIONS using sentinel keys for GLOBAL scope\n",
    "session.sql(f\"\"\"\n",
    "merge into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_CHAMPIONS t\n",
    "using (\n",
    "  select\n",
    "    {asof}::number as asof_fiscal_yyyymm,\n",
    "    'GLOBAL'::string as champion_scope,\n",
    "    '__ALL__'::string as roll_up_shop,\n",
    "    '__ALL__'::string as reason_group,\n",
    "    '{champ_mrid}'::string as model_run_id,\n",
    "    'WAPE_MICRO_OVERALL'::string as selection_metric,\n",
    "    object_construct(\n",
    "      'series_agg','MICRO',\n",
    "      'metric_scope','OVERALL',\n",
    "      'metric','WAPE',\n",
    "      'wape', {champ_wape},\n",
    "      'eval_anchors', {anchor_array_sql},\n",
    "      'mape_epsilon', {MAPE_EPSILON},\n",
    "      'run_id', '{RUN_ID}',\n",
    "      'candidate', '{champ_candidate}'\n",
    "    ) as selection_logic,\n",
    "    current_timestamp() as selected_at,\n",
    "    current_user() as selected_by\n",
    ") s\n",
    "on  t.asof_fiscal_yyyymm = s.asof_fiscal_yyyymm\n",
    "and t.champion_scope     = s.champion_scope\n",
    "and t.roll_up_shop       = s.roll_up_shop\n",
    "and t.reason_group       = s.reason_group\n",
    "when matched then update set\n",
    "  model_run_id      = s.model_run_id,\n",
    "  selection_metric  = s.selection_metric,\n",
    "  selection_logic   = s.selection_logic,\n",
    "  selected_at       = s.selected_at,\n",
    "  selected_by       = s.selected_by\n",
    "when not matched then insert (\n",
    "  asof_fiscal_yyyymm, champion_scope, roll_up_shop, reason_group,\n",
    "  model_run_id, selection_metric, selection_logic, selected_at, selected_by\n",
    ") values (\n",
    "  s.asof_fiscal_yyyymm, s.champion_scope, s.roll_up_shop, s.reason_group,\n",
    "  s.model_run_id, s.selection_metric, s.selection_logic, s.selected_at, s.selected_by\n",
    ")\n",
    "\"\"\").collect()\n",
    "\n",
    "print(\"Champion upserted into FORECAST_MODEL_CHAMPIONS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde8d42-0645-477a-a68c-ce50bc1b8aa5",
   "metadata": {
    "language": "python",
    "name": "whats_wrong_ridge_1"
   },
   "outputs": [],
   "source": [
    "mrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "select\n",
    "  r.params:\"candidate\"::string as candidate,\n",
    "  p.model_run_id,\n",
    "  count(*) as n,\n",
    "  min(p.y_true) as y_true_min,\n",
    "  avg(p.y_true) as y_true_avg,\n",
    "  max(p.y_true) as y_true_max,\n",
    "  min(p.y_pred) as y_pred_min,\n",
    "  avg(p.y_pred) as y_pred_avg,\n",
    "  max(p.y_pred) as y_pred_max,\n",
    "  sum(abs(p.y_true - p.y_pred)) / nullif(sum(abs(p.y_true)),0) as wape\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS p\n",
    "join DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS r\n",
    "  on r.model_run_id = p.model_run_id\n",
    "where p.model_run_id in ({mrid_list_sql})\n",
    "  and p.anchor_month_seq in (48)\n",
    "group by 1,2\n",
    "order by wape\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfdc00-f32e-4b1a-838f-095138dd4135",
   "metadata": {
    "language": "python",
    "name": "whats_wrong_ridge_2"
   },
   "outputs": [],
   "source": [
    "ridge_mrid = session.sql(f\"\"\"\n",
    "select model_run_id\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\n",
    "where run_id = '{RUN_ID}'\n",
    "  and params:\"candidate\"::string = 'RIDGE_OHE'\n",
    "limit 1\n",
    "\"\"\").to_pandas().iloc[0][\"MODEL_RUN_ID\"]\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "select\n",
    "  roll_up_shop,\n",
    "  reason_group,\n",
    "  anchor_fiscal_yyyymm,\n",
    "  horizon,\n",
    "  y_true,\n",
    "  y_pred,\n",
    "  (y_true - y_pred) as err,\n",
    "  abs(y_true - y_pred) as abs_err\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "where model_run_id = '{ridge_mrid}'\n",
    "  and anchor_month_seq in (48)\n",
    "order by abs_err desc\n",
    "limit 30\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c926fa5e-a4af-42cf-b18f-22fa6d20ef32",
   "metadata": {
    "language": "python",
    "name": "whats_wrong_ridge_3"
   },
   "outputs": [],
   "source": [
    "EPS = 100  # your epsilon\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "with p as (\n",
    "  select y_true, y_pred\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "  where model_run_id = '{ridge_mrid}'\n",
    "    and anchor_month_seq in (48)\n",
    "),\n",
    "t as (\n",
    "  select\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    -- signed log transform of y_true\n",
    "    case\n",
    "      when y_true >= 0 then ln(1 + abs(y_true)/{EPS})\n",
    "      else -ln(1 + abs(y_true)/{EPS})\n",
    "    end as y_true_slog\n",
    "  from p\n",
    ")\n",
    "select\n",
    "  avg(abs(y_pred - y_true)) as avg_abs_err_on_raw,\n",
    "  avg(abs(y_pred - y_true_slog)) as avg_abs_err_on_slog,\n",
    "  corr(y_pred, y_true) as corr_raw,\n",
    "  corr(y_pred, y_true_slog) as corr_slog\n",
    "from t\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1334bfc3-17af-4031-87f6-7621d143f93b",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "ridge_mrid = \"6673357e-8195-4146-9e36-17209b6cca57\"  # from 13A\n",
    "\n",
    "session.sql(f\"\"\"\n",
    "select\n",
    "  count(*) as n,\n",
    "  min(y_true) as y_true_min,\n",
    "  avg(y_true) as y_true_avg,\n",
    "  max(y_true) as y_true_max,\n",
    "  min(y_pred) as y_pred_min,\n",
    "  avg(y_pred) as y_pred_avg,\n",
    "  max(y_pred) as y_pred_max\n",
    "from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "where model_run_id = '{ridge_mrid}'\n",
    "  and anchor_month_seq = 48\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1ae06-268b-4585-a5c5-3a67d4d0f9b5",
   "metadata": {
    "language": "python",
    "name": "patch_ridge"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_mrid = \"6673357e-8195-4146-9e36-17209b6cca57\"\n",
    "EVAL_ANCHORS = [48]\n",
    "TRAIN_MAX_ANCHOR = min(EVAL_ANCHORS) - 1\n",
    "\n",
    "# Load dataset snap for this RUN_ID\n",
    "ds = session.sql(f\"\"\"\n",
    "  select *\n",
    "  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_DATASET_PC_REASON_H_SNAP\n",
    "  where run_id = '{RUN_ID}'\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "# Target + IDs\n",
    "y_col = \"Y_REVENUE\"\n",
    "id_cols = [\"RUN_ID\",\"ROLL_UP_SHOP\",\"REASON_GROUP\",\"ANCHOR_FISCAL_YYYYMM\",\"ANCHOR_MONTH_SEQ\",\n",
    "           \"TARGET_FISCAL_YYYYMM\",\"TARGET_MONTH_SEQ\",\"HORIZON\"]\n",
    "\n",
    "# Base feature set (start from your earlier computed cols, but re-derive safely)\n",
    "base_exclude = set(id_cols + [y_col])\n",
    "\n",
    "feature_cols = [c for c in ds.columns if c not in base_exclude]\n",
    "\n",
    "# Split numeric vs categorical\n",
    "cat_cols = [c for c in feature_cols if ds[c].dtype == \"object\"]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "# Ensure series identifiers are categorical features\n",
    "for c in [\"ROLL_UP_SHOP\",\"REASON_GROUP\"]:\n",
    "    if c not in cat_cols:\n",
    "        cat_cols.append(c)\n",
    "\n",
    "# Drop ID-like / key-like numeric columns that break linear models\n",
    "DROP_NUM = set([\n",
    "    \"ASOF_FISCAL_YYYYMM\",\n",
    "    \"ANCHOR_FISCAL_YYYYMM\",\n",
    "    \"TARGET_FISCAL_YYYYMM\",\n",
    "    \"ANCHOR_MONTH_SEQ\",\n",
    "    \"TARGET_MONTH_SEQ\",\n",
    "    \"ANCHOR_FISCAL_YEAR\",\n",
    "    \"ANCHOR_FISCAL_MONTH\",\n",
    "])\n",
    "num_cols = [c for c in num_cols if c not in DROP_NUM]\n",
    "\n",
    "print(\"Ridge numeric cols:\", len(num_cols))\n",
    "print(\"Ridge categorical cols:\", len(cat_cols))\n",
    "\n",
    "# Train/test split by anchor\n",
    "train = ds[ds[\"ANCHOR_MONTH_SEQ\"] <= TRAIN_MAX_ANCHOR].copy()\n",
    "test  = ds[ds[\"ANCHOR_MONTH_SEQ\"].isin(EVAL_ANCHORS)].copy()\n",
    "\n",
    "X_train = train[num_cols + cat_cols]\n",
    "y_train = train[y_col].astype(float)\n",
    "\n",
    "X_test  = test[num_cols + cat_cols]\n",
    "y_test  = test[y_col].astype(float)\n",
    "\n",
    "# Pipeline: impute + scale numeric, OHE categorical\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ]), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "model = Ridge(alpha=1.0, random_state=0)\n",
    "\n",
    "pipe = Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# Build prediction rows (match table columns dynamically)\n",
    "pred = test[id_cols].copy()\n",
    "pred[\"MODEL_RUN_ID\"] = ridge_mrid\n",
    "pred[\"Y_TRUE\"] = y_test.values\n",
    "pred[\"Y_PRED\"] = y_pred\n",
    "pred[\"BUILT_AT\"] = np.datetime64(\"now\")\n",
    "\n",
    "# Align to actual prediction table columns\n",
    "pred_cols = session.sql(\"\"\"\n",
    "select column_name\n",
    "from DB_BI_P_SANDBOX.INFORMATION_SCHEMA.COLUMNS\n",
    "where table_schema='SANDBOX'\n",
    "  and table_name='FORECAST_MODEL_BACKTEST_PREDICTIONS'\n",
    "order by ordinal_position\n",
    "\"\"\").to_pandas()[\"COLUMN_NAME\"].tolist()\n",
    "pred_cols_set = set(pred_cols)\n",
    "\n",
    "# keep only columns that exist in the table (case-sensitive to Snowflake output)\n",
    "# our pandas cols are uppercase already; if not, upper them\n",
    "pred.columns = [c.upper() for c in pred.columns]\n",
    "pred = pred[[c for c in pred.columns if c in pred_cols_set]]\n",
    "\n",
    "# Overwrite Ridge rows for these anchors (rerunnable)\n",
    "session.sql(f\"\"\"\n",
    "delete from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n",
    "where model_run_id = '{ridge_mrid}'\n",
    "  and anchor_month_seq in ({\",\".join([str(x) for x in EVAL_ANCHORS])})\n",
    "\"\"\").collect()\n",
    "\n",
    "session.create_dataframe(pred).write.mode(\"append\").save_as_table(\n",
    "    \"DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\"\n",
    ")\n",
    "\n",
    "print(\"Ridge predictions overwritten for anchors:\", EVAL_ANCHORS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  },
  "lastEditStatus": {
   "authorEmail": "nbalje@ccbcc.com",
   "authorId": "3300832511315",
   "authorName": "NBALJE",
   "lastEditTime": 1769777279630,
   "notebookId": "yhx54rbpsuqcaueaon3g",
   "sessionId": "794ae108-f49e-4d07-a8c4-02a90b022d05"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
