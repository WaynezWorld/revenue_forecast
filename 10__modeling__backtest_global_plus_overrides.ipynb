{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "yhx54rbpsuqcaueaon3g",
   "authorId": "3300832511315",
   "authorName": "NBALJE",
   "authorEmail": "nbalje@ccbcc.com",
   "sessionId": "794ae108-f49e-4d07-a8c4-02a90b022d05",
   "lastEditTime": 1769777279630
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "086a6fde-bdb3-46c7-8a32-f73e3a3aba04",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "import json\nimport uuid\nfrom datetime import datetime\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "parameters"
   },
   "source": "# === PARAMETERS ===\nRUN_ID = None  # set to a specific run_id string if you want; otherwise we'll auto-pick latest SUCCEEDED\nASOF_SCOPE = \"GLOBAL__WAPE_MICRO_OVERALL\"\nOVERRIDE_SCOPE = \"PC_REASON__WAPE_MICRO_OVERALL__OVERRIDE5PCT\"\nEPS = 100.0\nMAX_HORIZON = 12\nEVAL_ANCHORS = 12               # last 12 anchors (months) to backtest\nOVERRIDE_MIN_REL_IMPROV = 0.05  # 5%\nMAPE_EPSILON = 100              # per your decision\nBIAS_MAX_ABS = 0.02             # 2% guardrail (tunable)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "latest"
   },
   "source": "from snowflake.snowpark.functions import col\nimport pandas as pd\nimport uuid\nfrom datetime import datetime\n\n# Snowflake notebook usually provides `session`\nif RUN_ID is None:\n    df = session.sql(\"\"\"\n      select run_id\n      from DB_BI_P_SANDBOX.SANDBOX.FORECAST_RUNS\n      where status = 'SUCCEEDED'\n      order by triggered_at desc\n      limit 1\n    \"\"\").to_pandas()\n    RUN_ID = df.iloc[0][\"RUN_ID\"]\n\nasof = session.sql(f\"\"\"\n  select asof_fiscal_yyyymm\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_RUNS\n  where run_id = '{RUN_ID}'\n\"\"\").to_pandas().iloc[0][\"ASOF_FISCAL_YYYYMM\"]\n\nprint(\"RUN_ID:\", RUN_ID)\nprint(\"ASOF:\", asof)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "experiment_row_register_models"
   },
   "source": "EXPERIMENT_ID = \"EXP_GLOBAL_3A_V1\"\nnow = datetime.utcnow()\n\nsession.sql(f\"\"\"\nmerge into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_EXPERIMENTS t\nusing (select '{EXPERIMENT_ID}' experiment_id) s\non t.experiment_id = s.experiment_id\nwhen not matched then insert (experiment_id, experiment_name, experiment_desc, created_by, created_at, tags)\nvalues (\n  '{EXPERIMENT_ID}',\n  'Global candidates + per-series overrides (3A)',\n  'Train global candidate models; choose global champion + per-series overrides by WAPE improvement.',\n  current_user(), current_timestamp(),\n  parse_json('{{\"type\":\"3A\",\"mape_epsilon\":{MAPE_EPSILON},\"override_min_rel_improv\":{OVERRIDE_MIN_REL_IMPROV}}}')\n);\n\"\"\").collect()\n\ndef new_model_run_id():\n    return str(uuid.uuid4())\n\nCANDIDATES = [\n    # baseline: seasonal naive (computed in SQL; no sklearn needed)\n    {\"name\": \"SEASONAL_NAIVE_LAG12\", \"family\": \"baseline\", \"params\": {\"kind\": \"seasonal_naive_lag12\"}},\n    # ridge regression\n    {\"name\": \"RIDGE_OHE\", \"family\": \"ridge\", \"params\": {\"alpha\": 1.0, \"target_transform\": \"signed_log1p\"}},\n    # gradient boosting (sklearn)\n    {\"name\": \"GBR_OHE\", \"family\": \"gbr\", \"params\": {\"target_transform\": \"signed_log1p\"}},\n]\n\nmodel_runs = []\nfor c in CANDIDATES:\n    mrid = new_model_run_id()\n    model_runs.append((c, mrid))\n    session.sql(f\"\"\"\n      insert into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\n      (model_run_id, run_id, asof_fiscal_yyyymm, experiment_id, model_scope, model_family, feature_set_id,\n       target_name, max_horizon, params, training_env, status, started_at, updated_at)\n      select\n        '{mrid}', '{RUN_ID}', {asof}, '{EXPERIMENT_ID}', 'GLOBAL',\n        '{c[\"family\"]}', 'fs_v1', 'TOTAL_REVENUE', {MAX_HORIZON},\n        parse_json('{json.dumps({\"candidate\": c[\"name\"], **c[\"params\"], \"mape_epsilon\": MAPE_EPSILON, \"eval_anchors\": EVAL_ANCHORS})}'),\n        parse_json('{{\"runner\":\"snowflake_notebook\"}}'),\n        'STARTED', current_timestamp(), current_timestamp();\n    \"\"\").collect()\n\nprint(\"Registered model_run_ids:\")\nfor c, mrid in model_runs:\n    print(c[\"name\"], mrid)\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0408d0c8-563c-43be-b8d0-e6dd930d10dd",
   "metadata": {
    "language": "python",
    "name": "load_snap_features"
   },
   "outputs": [],
   "source": "import numpy as np\nimport json\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import GradientBoostingRegressor\n\nds = session.sql(f\"\"\"\n  select *\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_DATASET_PC_REASON_H_SNAP\n  where run_id = '{RUN_ID}'\n\"\"\").to_pandas()\n\n# ---- Column map (case-safe) ----\nlower_cols = {c.lower(): c for c in ds.columns}\n\n# ---- Required ID columns (use actual column names from the table) ----\nrequired = [\n    \"roll_up_shop\",\n    \"reason_group\",\n    \"anchor_fiscal_yyyymm\",\n    \"anchor_month_seq\",\n    \"target_fiscal_yyyymm\",\n    \"target_month_seq\",\n    \"horizon\",\n    \"run_id\",\n]\nmissing = [c for c in required if c not in lower_cols]\nif missing:\n    raise ValueError(f\"Dataset snap missing required columns: {missing}\")\n\nid_cols = [lower_cols[c] for c in required]\n\n# ---- Target column (explicit) ----\ny_col = \"Y_REVENUE\"\nif y_col not in ds.columns:\n    raise ValueError(f\"Target column '{y_col}' not found. Available columns: {ds.columns.tolist()}\")\n\nprint(\"Using y_col:\", y_col)\nprint(\"ID cols:\", id_cols)\n\n# ---- Feature selection ----\n# Exclude IDs + target. Also exclude bookkeeping columns you don't want as model inputs.\nexclude_cols = set(id_cols + [y_col, \"BUILT_AT\", \"ROW_HASH\"])\n\n# Optional: exclude BUDGET_TARGET from features to prevent \"cheating\" during backtest\n# if budget is not truly known at prediction time in your process. If budget is always known, remove this line.\n# exclude_cols.add(\"BUDGET_TARGET\")\n\nfeature_cols = [c for c in ds.columns if c not in exclude_cols]\n\n# Split categorical vs numeric\ncat_cols = [c for c in feature_cols if ds[c].dtype == \"object\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\n# Ensure series identifiers are included as categorical features for GLOBAL models\nfor c in [\"ROLL_UP_SHOP\", \"REASON_GROUP\"]:\n    if c in ds.columns and c not in cat_cols:\n        cat_cols.append(c)\n        if c in num_cols:\n            num_cols.remove(c)\n\nprint(\"Numeric features:\", len(num_cols))\nprint(\"Categorical features:\", len(cat_cols))\nprint(\"Example numeric cols:\", num_cols[:10])\nprint(\"Example categorical cols:\", cat_cols[:10])\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "898ca3b5-e662-4474-b25f-d497922ae7f4",
   "metadata": {
    "language": "python",
    "name": "add_horizon_feature"
   },
   "outputs": [],
   "source": "# Add HORIZON as a numeric feature (we want one global model across horizons)\nif \"HORIZON\" not in num_cols:\n    num_cols.append(\"HORIZON\")\n\n# Fill nulls defensively\nds[num_cols] = ds[num_cols].fillna(0)\nds[cat_cols] = ds[cat_cols].fillna(\"UNKNOWN\")\n\nprint(\"Numeric features (post):\", len(num_cols))\nprint(\"Categorical features (post):\", len(cat_cols))\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bef96b19-f7ee-4f2c-81b9-a4ecdca1036e",
   "metadata": {
    "language": "python",
    "name": "log_helpers_model_factory"
   },
   "outputs": [],
   "source": "import numpy as np\n\ndef signed_log1p(x, eps: float):\n    \"\"\"\n    Signed log transform:\n      y = sign(x) * log1p(|x| / eps)\n\n    eps > 0 controls how aggressive the compression is.\n    \"\"\"\n    if eps is None or eps <= 0:\n        raise ValueError(\"eps must be > 0\")\n\n    x = np.asarray(x, dtype=float)\n    return np.sign(x) * np.log1p(np.abs(x) / eps)\n\ndef signed_expm1(y, eps: float):\n    \"\"\"\n    Inverse of signed_log1p:\n      x = sign(y) * eps * (expm1(|y|))\n    \"\"\"\n    if eps is None or eps <= 0:\n        raise ValueError(\"eps must be > 0\")\n\n    y = np.asarray(y, dtype=float)\n    return np.sign(y) * eps * np.expm1(np.abs(y))\n\ndef signed_log10_1p(x, eps: float):\n    \"\"\"\n    Optional (not used yet): signed log10 variant.\n      y = sign(x) * log10(1 + |x|/eps)\n    \"\"\"\n    if eps is None or eps <= 0:\n        raise ValueError(\"eps must be > 0\")\n\n    x = np.asarray(x, dtype=float)\n    return np.sign(x) * np.log10(1.0 + (np.abs(x) / eps))\n\ndef signed_pow10_m1(y, eps: float):\n    \"\"\"\n    Inverse of signed_log10_1p:\n      x = sign(y) * eps * ((10^|y|) - 1)\n    \"\"\"\n    if eps is None or eps <= 0:\n        raise ValueError(\"eps must be > 0\")\n\n    y = np.asarray(y, dtype=float)\n    return np.sign(y) * eps * (np.power(10.0, np.abs(y)) - 1.0)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cdeaeec-ace1-426b-84a4-dad354473fc9",
   "metadata": {
    "language": "python",
    "name": "resolve_anchors_clear_prior_preds"
   },
   "outputs": [],
   "source": "import pandas as pd\nfrom datetime import datetime\n\nanchor_seq_col = \"ANCHOR_MONTH_SEQ\"\ntarget_seq_col = \"TARGET_MONTH_SEQ\"\npc_col = \"ROLL_UP_SHOP\"\nrg_col = \"REASON_GROUP\"\nh_col = \"HORIZON\"\n\ny_col = \"Y_REVENUE\"  # explicit\n\nanchors = sorted(ds[anchor_seq_col].unique())\neval_anchors = anchors[-EVAL_ANCHORS:]  # last 12 anchors\n\nprint(\"Anchors min/max:\", min(anchors), max(anchors))\nprint(\"Eval anchors:\", eval_anchors)\n\n# Identify model_run_ids from earlier registration cell\nMODEL_RUN_IDS = [mrid for (_, mrid) in model_runs]\nprint(\"MODEL_RUN_IDS:\", MODEL_RUN_IDS)\n\n# Clear prior predictions for these model_run_ids (rerunnable)\nmrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\nsession.sql(f\"\"\"\ndelete from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\nwhere model_run_id in ({mrid_list_sql});\n\"\"\").collect()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ebfbde6a-3662-4ada-8cdb-77a93aad5ed8",
   "metadata": {
    "language": "python",
    "name": "backtest_RIDGE_GBR"
   },
   "outputs": [],
   "source": "from datetime import datetime\nimport pandas as pd\nimport numpy as np\n\npred_rows = []\nnow = datetime.utcnow()\n\n# ---- Ensure eval_anchors are plain ints (avoid np.int8 etc) ----\neval_anchors = [int(x) for x in eval_anchors]\n\n# ---- Ensure model_runs exists (donâ€™t rely on hidden state) ----\n# Expected upstream vars (depending on your notebook):\n# - candidates: list[dict] with {\"name\": ...}\n# - model_run_ids: dict mapping name -> uuid\nif \"model_runs\" not in globals() or model_runs is None:\n    if \"candidates\" in globals() and \"model_run_ids\" in globals():\n        model_runs = [(c, model_run_ids[c[\"name\"]]) for c in candidates if c.get(\"name\") in model_run_ids]\n    elif \"CANDIDATES\" in globals() and \"model_run_ids\" in globals():\n        model_runs = [(c, model_run_ids[c[\"name\"]]) for c in CANDIDATES if c.get(\"name\") in model_run_ids]\n    else:\n        raise NameError(\n            \"model_runs is not defined and could not be inferred. \"\n            \"Define `model_runs = [(candidate_dict, model_run_id), ...]` in experiment_row_register_models.\"\n        )\n\n# Also keep a convenience list for later leaderboard cells\nMODEL_RUN_IDS = [mrid for _, mrid in model_runs]\n\n# Optional: only used if you want to prevent huge Ridge blowups in transformed space.\nRIDGE_SLOG_CLIP_MARGIN = 0.25\n\nfor (cand, mrid) in model_runs:\n    cname = cand[\"name\"]\n    if cname == \"SEASONAL_NAIVE_LAG12\":\n        continue  # baseline handled in SQL\n\n    pipe = make_model(cname)\n\n    for a in eval_anchors:\n        # Train on rows whose targets would have been known at anchor a:\n        train = ds[(ds[target_seq_col] <= a)].copy()\n        test  = ds[(ds[anchor_seq_col] == a)].copy()\n\n        # drop null targets defensively\n        train = train[train[y_col].notna()]\n        test  = test[test[y_col].notna()]\n\n        if train.empty or test.empty:\n            continue\n\n        X_train = train[num_cols + cat_cols]\n        X_test  = test[num_cols + cat_cols]\n\n        y_train = train[y_col].astype(float).to_numpy()\n\n        # ---- Transform with explicit EPS from parameters ----\n        y_train_t = signed_log1p(y_train, eps=EPS)\n\n        # Optional guard: clip for Ridge only (helps prevent extreme extrapolation)\n        if cname.upper().startswith(\"RIDGE\"):\n            lo = np.nanmin(y_train_t) - RIDGE_SLOG_CLIP_MARGIN\n            hi = np.nanmax(y_train_t) + RIDGE_SLOG_CLIP_MARGIN\n\n        pipe.fit(X_train, y_train_t)\n        yhat_t = pipe.predict(X_test)\n\n        if cname.upper().startswith(\"RIDGE\"):\n            yhat_t = np.clip(yhat_t, lo, hi)\n\n        yhat = signed_expm1(yhat_t, eps=EPS)\n\n        # Append row-wise predictions for Snowflake table\n        for j, (_, r) in enumerate(test.iterrows()):\n            pred_rows.append({\n                \"MODEL_RUN_ID\": mrid,\n                \"ROLL_UP_SHOP\": str(r[pc_col]),\n                \"REASON_GROUP\": str(r[rg_col]),\n                \"ANCHOR_FISCAL_YYYYMM\": int(r[\"ANCHOR_FISCAL_YYYYMM\"]),\n                \"ANCHOR_MONTH_SEQ\": int(r[anchor_seq_col]),\n                \"HORIZON\": int(r[h_col]),\n                \"TARGET_FISCAL_YYYYMM\": int(r[\"TARGET_FISCAL_YYYYMM\"]),\n                \"TARGET_MONTH_SEQ\": int(r[target_seq_col]),\n                \"Y_TRUE\": float(r[y_col]),\n                \"Y_PRED\": float(yhat[j]),\n                \"Y_PRED_LO\": None,\n                \"Y_PRED_HI\": None,\n                \"CREATED_AT\": now,\n                \"DETAILS\": {\"eps\": float(EPS), \"candidate\": cname, \"eval_anchor\": int(a)}\n            })\n\npred_df = pd.DataFrame(pred_rows)\nprint(\"Python prediction rows:\", len(pred_df))\npred_df.head()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65aeb222-90a2-4334-9371-2bfdc883b41f",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "print(\"EPS:\", EPS)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e33b788b-a0cf-4c92-8d6c-560f6b85caf2",
   "metadata": {
    "language": "python",
    "name": "write_to_sql"
   },
   "outputs": [],
   "source": "if len(pred_df) > 0:\n    session.write_pandas(\n        pred_df,\n        table_name=\"FORECAST_MODEL_BACKTEST_PREDICTIONS\",\n        database=\"DB_BI_P_SANDBOX\",\n        schema=\"SANDBOX\",\n        auto_create_table=False,\n        overwrite=False\n    )\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c78d20d4-caf0-4298-9347-45451a900e04",
   "metadata": {
    "language": "python",
    "name": "get_columns"
   },
   "outputs": [],
   "source": "# Detect column names in FORECAST_ACTUALS_PC_REASON_MTH_SNAP (no guessing)\ncols = session.sql(\"\"\"\nselect column_name\nfrom DB_BI_P_SANDBOX.INFORMATION_SCHEMA.COLUMNS\nwhere table_schema = 'SANDBOX'\n  and table_name   = 'FORECAST_ACTUALS_PC_REASON_MTH_SNAP'\norder by ordinal_position\n\"\"\").to_pandas()[\"COLUMN_NAME\"].tolist()\n\nprint(\"ACTUALS_SNAP columns:\", cols)\n\n# Find the month sequence column\nif \"MONTH_SEQ\" in cols:\n    actuals_seq_col = \"MONTH_SEQ\"\nelse:\n    raise ValueError(\"Could not find MONTH_SEQ in FORECAST_ACTUALS_PC_REASON_MTH_SNAP. Paste the column list above.\")\n\n# Find the revenue/actual value column (ordered candidates)\nactual_candidates = [\n    \"REVENUE\", \"ACTUAL_REVENUE\", \"Y_REVENUE\", \"TOTAL_REVENUE\",\n    \"REVENUE_MTH\", \"ACTUALS_REVENUE\", \"ACTUAL\"\n]\nactuals_y_col = next((c for c in actual_candidates if c in cols), None)\n\nif actuals_y_col is None:\n    raise ValueError(\n        \"Could not find an actuals revenue column in FORECAST_ACTUALS_PC_REASON_MTH_SNAP. \"\n        f\"Columns are: {cols}\"\n    )\n\nprint(\"Using actuals_seq_col:\", actuals_seq_col)\nprint(\"Using actuals_y_col:\", actuals_y_col)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9d7e1b15-52b0-4712-a7cd-046b7ff187a1",
   "metadata": {
    "language": "python",
    "name": "baseline_seasonal_naive"
   },
   "outputs": [],
   "source": "baseline_mrid = [mrid for (c, mrid) in model_runs if c[\"name\"] == \"SEASONAL_NAIVE_LAG12\"][0]\n\nsession.sql(f\"\"\"\ninsert into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n(model_run_id, roll_up_shop, reason_group,\n anchor_fiscal_yyyymm, anchor_month_seq, horizon,\n target_fiscal_yyyymm, target_month_seq,\n y_true, y_pred, y_pred_lo, y_pred_hi,\n created_at, details)\nwith ds as (\n  select *\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_DATASET_PC_REASON_H_SNAP\n  where run_id = '{RUN_ID}'\n),\neval_anchors as (\n  select distinct ds.anchor_month_seq as anchor_month_seq\n  from ds\n  qualify dense_rank() over (order by ds.anchor_month_seq desc) <= {EVAL_ANCHORS}\n),\nbase as (\n  select\n    ds.roll_up_shop,\n    ds.reason_group,\n    ds.anchor_fiscal_yyyymm,\n    ds.anchor_month_seq,\n    ds.horizon,\n    ds.target_fiscal_yyyymm,\n    ds.target_month_seq,\n    ds.y_revenue::number as y_true\n  from ds\n  join eval_anchors ea\n    on ea.anchor_month_seq = ds.anchor_month_seq\n),\nlag12 as (\n  select\n    a.roll_up_shop,\n    a.reason_group,\n    a.{actuals_seq_col} as month_seq,\n    a.{actuals_y_col}   as y_lag12\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_ACTUALS_PC_REASON_MTH_SNAP a\n  where a.run_id = '{RUN_ID}'\n)\nselect\n  '{baseline_mrid}',\n  b.roll_up_shop, b.reason_group,\n  b.anchor_fiscal_yyyymm, b.anchor_month_seq, b.horizon,\n  b.target_fiscal_yyyymm, b.target_month_seq,\n  b.y_true,\n  l.y_lag12 as y_pred,\n  null, null,\n  current_timestamp(),\n  parse_json('{{\"baseline\":\"seasonal_naive_lag12\"}}')\nfrom base b\nleft join lag12 l\n  on l.roll_up_shop = b.roll_up_shop\n and l.reason_group = b.reason_group\n and l.month_seq = (b.target_month_seq - 12);\n\"\"\").collect()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0a725d6b-a6ac-4bcb-8a6b-86b738921cbe",
   "metadata": {
    "language": "python",
    "name": "validate_prediction_coverage"
   },
   "outputs": [],
   "source": "# Show how many backtest predictions we have per model_run_id\nmrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n\nsession.sql(f\"\"\"\nselect\n  model_run_id,\n  count(*) as rows_pred,\n  count_if(y_pred is null) as null_preds,\n  count_if(y_true is null) as null_true,\n  min(anchor_month_seq) as min_anchor_seq,\n  max(anchor_month_seq) as max_anchor_seq,\n  min(horizon) as min_h,\n  max(horizon) as max_h\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\nwhere model_run_id in ({mrid_list_sql})\ngroup by 1\norder by 1\n\"\"\").show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b102f555-6b4c-406d-8095-2967844a103d",
   "metadata": {
    "language": "python",
    "name": "horizon_coverage"
   },
   "outputs": [],
   "source": "# Horizon coverage by anchor for ONE model_run_id (pick any; they should match)\none_mrid = MODEL_RUN_IDS[0]\n\nsession.sql(f\"\"\"\nselect\n  anchor_month_seq,\n  count(*) as rowz,\n  count(distinct horizon) as horizons_present,\n  min(horizon) as min_h,\n  max(horizon) as max_h,\n  min(target_month_seq) as min_target_seq,\n  max(target_month_seq) as max_target_seq\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\nwhere model_run_id = '{one_mrid}'\ngroup by 1\norder by 1\n\"\"\").show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63ec5246-b359-4b20-868f-bc7d9730e922",
   "metadata": {
    "language": "python",
    "name": "fixed_grid"
   },
   "outputs": [],
   "source": "one_mrid = session.sql(f\"\"\"\n  select model_run_id\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\n  where run_id = '{RUN_ID}'\n  order by started_at desc\n  limit 1\n\"\"\").to_pandas().iloc[0,0]\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f780cda-762f-41e7-8afb-51e5051fdea6",
   "metadata": {
    "language": "python",
    "name": "compute_metrics"
   },
   "outputs": [],
   "source": "# --- Inputs ---\nfixed_eval_anchors = [48]\nanchor_list_sql = \", \".join([str(x) for x in fixed_eval_anchors])\nanchor_array_sql = \"array_construct(\" + \", \".join([str(x) for x in fixed_eval_anchors]) + \")\"\n\nmrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n\nbaseline_mrid = [mrid for (c, mrid) in model_runs if c[\"name\"] == \"SEASONAL_NAIVE_LAG12\"][0]\n\n# --- Clear existing metrics for reruns ---\nsession.sql(f\"\"\"\ndelete from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS\nwhere model_run_id in ({mrid_list_sql})\n\"\"\").collect()\n\n# --- Compute + insert metrics (note: INSERT ... WITH ... SELECT ...) ---\nsession.sql(f\"\"\"\ninsert into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS\n(model_run_id, metric_scope, metric_name, horizon, value, computed_at, details)\n\nwith p as (\n  select *\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n  where model_run_id in ({mrid_list_sql})\n    and anchor_month_seq in ({anchor_list_sql})\n),\nnaive as (\n  select\n    roll_up_shop,\n    reason_group,\n    anchor_month_seq,\n    horizon,\n    abs(y_true - y_pred) as abs_naive_err\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n  where model_run_id = '{baseline_mrid}'\n    and anchor_month_seq in ({anchor_list_sql})\n),\np3 as (\n  select\n    p.*,\n    (p.y_true - p.y_pred) as err,\n    (p.y_pred - p.y_true) as err_signed,\n    abs(p.y_true - p.y_pred) as abs_err,\n    abs(p.y_true) as abs_y,\n    n.abs_naive_err\n  from p\n  left join naive n\n    on n.roll_up_shop = p.roll_up_shop\n   and n.reason_group = p.reason_group\n   and n.anchor_month_seq = p.anchor_month_seq\n   and n.horizon = p.horizon\n),\n\n-- MICRO\nmicro_overall as (\n  select\n    model_run_id,\n    'OVERALL' as metric_scope,\n    null::number as horizon,\n    avg(abs_err) as mae,\n    sqrt(avg(err*err)) as rmse,\n    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n    sum(err_signed) / nullif(sum(abs_y),0) as bias\n  from p3\n  group by 1\n),\nmicro_by_h as (\n  select\n    model_run_id,\n    'BY_HORIZON' as metric_scope,\n    horizon,\n    avg(abs_err) as mae,\n    sqrt(avg(err*err)) as rmse,\n    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n    sum(err_signed) / nullif(sum(abs_y),0) as bias\n  from p3\n  group by 1,3\n),\n\n-- MACRO (per series, then average)\nseries_overall as (\n  select\n    model_run_id,\n    roll_up_shop,\n    reason_group,\n    'OVERALL' as metric_scope,\n    null::number as horizon,\n    avg(abs_err) as mae,\n    sqrt(avg(err*err)) as rmse,\n    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n    sum(err_signed) / nullif(sum(abs_y),0) as bias\n  from p3\n  group by 1,2,3\n),\nseries_by_h as (\n  select\n    model_run_id,\n    roll_up_shop,\n    reason_group,\n    'BY_HORIZON' as metric_scope,\n    horizon,\n    avg(abs_err) as mae,\n    sqrt(avg(err*err)) as rmse,\n    sum(abs_err) / nullif(sum(abs_y),0) as wape,\n    avg(iff(abs_y >= {MAPE_EPSILON}, abs_err/abs_y, null)) as mape_eps,\n    avg(abs_err) / nullif(avg(abs_naive_err),0) as mase,\n    sum(err_signed) / nullif(sum(abs_y),0) as bias\n  from p3\n  group by 1,2,3,5\n),\nmacro_agg as (\n  select\n    model_run_id,\n    metric_scope,\n    horizon,\n    avg(mae) as mae,\n    avg(rmse) as rmse,\n    avg(wape) as wape,\n    avg(mape_eps) as mape_eps,\n    avg(mase) as mase,\n    avg(bias) as bias\n  from (\n    select model_run_id, metric_scope, horizon, mae, rmse, wape, mape_eps, mase, bias from series_overall\n    union all\n    select model_run_id, metric_scope, horizon, mae, rmse, wape, mape_eps, mase, bias from series_by_h\n  )\n  group by 1,2,3\n)\n\n-- Emit rows into FORECAST_MODEL_METRICS\nselect\n  model_run_id,\n  metric_scope,\n  metric_name,\n  horizon,\n  value,\n  current_timestamp(),\n  object_construct('series_agg','MICRO','eval_anchors',{anchor_array_sql},'mape_epsilon',{MAPE_EPSILON})\nfrom (\n  select model_run_id, metric_scope, horizon, 'MAE' as metric_name, mae as value from micro_overall\n  union all select model_run_id, metric_scope, horizon, 'RMSE', rmse from micro_overall\n  union all select model_run_id, metric_scope, horizon, 'WAPE', wape from micro_overall\n  union all select model_run_id, metric_scope, horizon, 'MAPE_EPS', mape_eps from micro_overall\n  union all select model_run_id, metric_scope, horizon, 'MASE', mase from micro_overall\n  union all select model_run_id, metric_scope, horizon, 'BIAS', bias from micro_overall\n\n  union all select model_run_id, metric_scope, horizon, 'MAE', mae from micro_by_h\n  union all select model_run_id, metric_scope, horizon, 'RMSE', rmse from micro_by_h\n  union all select model_run_id, metric_scope, horizon, 'WAPE', wape from micro_by_h\n  union all select model_run_id, metric_scope, horizon, 'MAPE_EPS', mape_eps from micro_by_h\n  union all select model_run_id, metric_scope, horizon, 'MASE', mase from micro_by_h\n  union all select model_run_id, metric_scope, horizon, 'BIAS', bias from micro_by_h\n)\n\nunion all\n\nselect\n  model_run_id,\n  metric_scope,\n  metric_name,\n  horizon,\n  value,\n  current_timestamp(),\n  object_construct('series_agg','MACRO','eval_anchors',{anchor_array_sql},'mape_epsilon',{MAPE_EPSILON})\nfrom (\n  select model_run_id, metric_scope, horizon, 'MAE' as metric_name, mae as value from macro_agg\n  union all select model_run_id, metric_scope, horizon, 'RMSE', rmse from macro_agg\n  union all select model_run_id, metric_scope, horizon, 'WAPE', wape from macro_agg\n  union all select model_run_id, metric_scope, horizon, 'MAPE_EPS', mape_eps from macro_agg\n  union all select model_run_id, metric_scope, horizon, 'MASE', mase from macro_agg\n  union all select model_run_id, metric_scope, horizon, 'BIAS', bias from macro_agg\n)\n\"\"\").collect()\n\nprint(\"Cell 11 done. Anchors:\", fixed_eval_anchors)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fccca2d9-28e3-4056-85be-eb37fb631dd8",
   "metadata": {
    "language": "python",
    "name": "leaderboard"
   },
   "outputs": [],
   "source": "# --- leaderboard (replace entire cell) ---\nmrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n\nsession.sql(f\"\"\"\nwith s as (\n  select\n    m.model_run_id,\n    r.params:\"candidate\"::string as candidate,\n    m.value as wape_micro_overall,\n    r.updated_at\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS m\n  join DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS r\n    on r.model_run_id = m.model_run_id\n  where m.model_run_id in ({mrid_list_sql})\n    and m.metric_scope = 'OVERALL'\n    and m.metric_name  = 'WAPE'\n    and m.details:\"series_agg\"::string = 'MICRO'\n),\nbest as (\n  select *\n  from s\n  qualify row_number() over (\n    partition by candidate\n    order by wape_micro_overall asc, updated_at desc\n  ) = 1\n)\nselect model_run_id, candidate, wape_micro_overall\nfrom best\norder by wape_micro_overall\n\"\"\").show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2765635c-f297-47f8-b86a-ba72a545d361",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "select\n  params:\"candidate\"::string as candidate,\n  model_run_id,\n  created_at\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\nwhere run_id = '6673357e-8195-4146-9e36-17209b6cca57'\n  and params:\"candidate\"::string = 'RIDGE_OHE'\norder by created_at;\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "358d07a9-dc56-409c-9247-a0a0355e2bb5",
   "metadata": {
    "language": "python",
    "name": "persist_champion"
   },
   "outputs": [],
   "source": "# --- Inputs you already have ---\n# RUN_ID, MODEL_RUN_IDS, MAPE_EPSILON, fixed_eval_anchors\nfixed_eval_anchors = [48]\nanchor_array_sql = \"array_construct(\" + \", \".join([str(x) for x in fixed_eval_anchors]) + \")\"\n\n# 1) Get ASOF_FISCAL_YYYYMM for this RUN_ID\nasof = session.sql(f\"\"\"\nselect asof_fiscal_yyyymm\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_RUNS\nwhere run_id = '{RUN_ID}'\n\"\"\").to_pandas().iloc[0][\"ASOF_FISCAL_YYYYMM\"]\n\n# 2) Pick champion by WAPE / MICRO / OVERALL (fixed-grid anchors already embedded in metrics.details)\nchamp = session.sql(f\"\"\"\nwith scores as (\n  select\n    m.model_run_id,\n    r.params:\"candidate\"::string as candidate,\n    m.value as wape_micro_overall\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_METRICS m\n  join DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS r\n    on r.model_run_id = m.model_run_id\n  where r.run_id = '{RUN_ID}'\n    and m.metric_scope = 'OVERALL'\n    and m.metric_name = 'WAPE'\n    and m.details:\"series_agg\"::string = 'MICRO'\n  order by wape_micro_overall\n)\nselect * from scores limit 1\n\"\"\").to_pandas()\n\nchamp_mrid = champ.iloc[0][\"MODEL_RUN_ID\"]\nchamp_candidate = champ.iloc[0][\"CANDIDATE\"]\nchamp_wape = float(champ.iloc[0][\"WAPE_MICRO_OVERALL\"])\n\nprint(\"Champion:\", champ_candidate, champ_mrid, \"WAPE=\", champ_wape, \"ASOF=\", asof)\n\n# 3) Upsert into FORECAST_MODEL_CHAMPIONS using sentinel keys for GLOBAL scope\nsession.sql(f\"\"\"\nmerge into DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_CHAMPIONS t\nusing (\n  select\n    {asof}::number as asof_fiscal_yyyymm,\n    'GLOBAL'::string as champion_scope,\n    '__ALL__'::string as roll_up_shop,\n    '__ALL__'::string as reason_group,\n    '{champ_mrid}'::string as model_run_id,\n    'WAPE_MICRO_OVERALL'::string as selection_metric,\n    object_construct(\n      'series_agg','MICRO',\n      'metric_scope','OVERALL',\n      'metric','WAPE',\n      'wape', {champ_wape},\n      'eval_anchors', {anchor_array_sql},\n      'mape_epsilon', {MAPE_EPSILON},\n      'run_id', '{RUN_ID}',\n      'candidate', '{champ_candidate}'\n    ) as selection_logic,\n    current_timestamp() as selected_at,\n    current_user() as selected_by\n) s\non  t.asof_fiscal_yyyymm = s.asof_fiscal_yyyymm\nand t.champion_scope     = s.champion_scope\nand t.roll_up_shop       = s.roll_up_shop\nand t.reason_group       = s.reason_group\nwhen matched then update set\n  model_run_id      = s.model_run_id,\n  selection_metric  = s.selection_metric,\n  selection_logic   = s.selection_logic,\n  selected_at       = s.selected_at,\n  selected_by       = s.selected_by\nwhen not matched then insert (\n  asof_fiscal_yyyymm, champion_scope, roll_up_shop, reason_group,\n  model_run_id, selection_metric, selection_logic, selected_at, selected_by\n) values (\n  s.asof_fiscal_yyyymm, s.champion_scope, s.roll_up_shop, s.reason_group,\n  s.model_run_id, s.selection_metric, s.selection_logic, s.selected_at, s.selected_by\n)\n\"\"\").collect()\n\nprint(\"Champion upserted into FORECAST_MODEL_CHAMPIONS\")\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9fde8d42-0645-477a-a68c-ce50bc1b8aa5",
   "metadata": {
    "language": "python",
    "name": "whats_wrong_ridge_1"
   },
   "outputs": [],
   "source": "mrid_list_sql = \", \".join([f\"'{x}'\" for x in MODEL_RUN_IDS])\n\nsession.sql(f\"\"\"\nselect\n  r.params:\"candidate\"::string as candidate,\n  p.model_run_id,\n  count(*) as n,\n  min(p.y_true) as y_true_min,\n  avg(p.y_true) as y_true_avg,\n  max(p.y_true) as y_true_max,\n  min(p.y_pred) as y_pred_min,\n  avg(p.y_pred) as y_pred_avg,\n  max(p.y_pred) as y_pred_max,\n  sum(abs(p.y_true - p.y_pred)) / nullif(sum(abs(p.y_true)),0) as wape\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS p\njoin DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS r\n  on r.model_run_id = p.model_run_id\nwhere p.model_run_id in ({mrid_list_sql})\n  and p.anchor_month_seq in (48)\ngroup by 1,2\norder by wape\n\"\"\").show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1bfdc00-f32e-4b1a-838f-095138dd4135",
   "metadata": {
    "language": "python",
    "name": "whats_wrong_ridge_2"
   },
   "outputs": [],
   "source": "ridge_mrid = session.sql(f\"\"\"\nselect model_run_id\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_RUNS\nwhere run_id = '{RUN_ID}'\n  and params:\"candidate\"::string = 'RIDGE_OHE'\nlimit 1\n\"\"\").to_pandas().iloc[0][\"MODEL_RUN_ID\"]\n\nsession.sql(f\"\"\"\nselect\n  roll_up_shop,\n  reason_group,\n  anchor_fiscal_yyyymm,\n  horizon,\n  y_true,\n  y_pred,\n  (y_true - y_pred) as err,\n  abs(y_true - y_pred) as abs_err\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\nwhere model_run_id = '{ridge_mrid}'\n  and anchor_month_seq in (48)\norder by abs_err desc\nlimit 30\n\"\"\").show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c926fa5e-a4af-42cf-b18f-22fa6d20ef32",
   "metadata": {
    "language": "python",
    "name": "whats_wrong_ridge_3"
   },
   "outputs": [],
   "source": "EPS = 100  # your epsilon\n\nsession.sql(f\"\"\"\nwith p as (\n  select y_true, y_pred\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\n  where model_run_id = '{ridge_mrid}'\n    and anchor_month_seq in (48)\n),\nt as (\n  select\n    y_true,\n    y_pred,\n    -- signed log transform of y_true\n    case\n      when y_true >= 0 then ln(1 + abs(y_true)/{EPS})\n      else -ln(1 + abs(y_true)/{EPS})\n    end as y_true_slog\n  from p\n)\nselect\n  avg(abs(y_pred - y_true)) as avg_abs_err_on_raw,\n  avg(abs(y_pred - y_true_slog)) as avg_abs_err_on_slog,\n  corr(y_pred, y_true) as corr_raw,\n  corr(y_pred, y_true_slog) as corr_slog\nfrom t\n\"\"\").show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1334bfc3-17af-4031-87f6-7621d143f93b",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "ridge_mrid = \"6673357e-8195-4146-9e36-17209b6cca57\"  # from 13A\n\nsession.sql(f\"\"\"\nselect\n  count(*) as n,\n  min(y_true) as y_true_min,\n  avg(y_true) as y_true_avg,\n  max(y_true) as y_true_max,\n  min(y_pred) as y_pred_min,\n  avg(y_pred) as y_pred_avg,\n  max(y_pred) as y_pred_max\nfrom DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\nwhere model_run_id = '{ridge_mrid}'\n  and anchor_month_seq = 48\n\"\"\").show()\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6df1ae06-268b-4585-a5c5-3a67d4d0f9b5",
   "metadata": {
    "language": "python",
    "name": "patch_ridge"
   },
   "outputs": [],
   "source": "import numpy as np\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Ridge\n\nridge_mrid = \"6673357e-8195-4146-9e36-17209b6cca57\"\nEVAL_ANCHORS = [48]\nTRAIN_MAX_ANCHOR = min(EVAL_ANCHORS) - 1\n\n# Load dataset snap for this RUN_ID\nds = session.sql(f\"\"\"\n  select *\n  from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_DATASET_PC_REASON_H_SNAP\n  where run_id = '{RUN_ID}'\n\"\"\").to_pandas()\n\n# Target + IDs\ny_col = \"Y_REVENUE\"\nid_cols = [\"RUN_ID\",\"ROLL_UP_SHOP\",\"REASON_GROUP\",\"ANCHOR_FISCAL_YYYYMM\",\"ANCHOR_MONTH_SEQ\",\n           \"TARGET_FISCAL_YYYYMM\",\"TARGET_MONTH_SEQ\",\"HORIZON\"]\n\n# Base feature set (start from your earlier computed cols, but re-derive safely)\nbase_exclude = set(id_cols + [y_col])\n\nfeature_cols = [c for c in ds.columns if c not in base_exclude]\n\n# Split numeric vs categorical\ncat_cols = [c for c in feature_cols if ds[c].dtype == \"object\"]\nnum_cols = [c for c in feature_cols if c not in cat_cols]\n\n# Ensure series identifiers are categorical features\nfor c in [\"ROLL_UP_SHOP\",\"REASON_GROUP\"]:\n    if c not in cat_cols:\n        cat_cols.append(c)\n\n# Drop ID-like / key-like numeric columns that break linear models\nDROP_NUM = set([\n    \"ASOF_FISCAL_YYYYMM\",\n    \"ANCHOR_FISCAL_YYYYMM\",\n    \"TARGET_FISCAL_YYYYMM\",\n    \"ANCHOR_MONTH_SEQ\",\n    \"TARGET_MONTH_SEQ\",\n    \"ANCHOR_FISCAL_YEAR\",\n    \"ANCHOR_FISCAL_MONTH\",\n])\nnum_cols = [c for c in num_cols if c not in DROP_NUM]\n\nprint(\"Ridge numeric cols:\", len(num_cols))\nprint(\"Ridge categorical cols:\", len(cat_cols))\n\n# Train/test split by anchor\ntrain = ds[ds[\"ANCHOR_MONTH_SEQ\"] <= TRAIN_MAX_ANCHOR].copy()\ntest  = ds[ds[\"ANCHOR_MONTH_SEQ\"].isin(EVAL_ANCHORS)].copy()\n\nX_train = train[num_cols + cat_cols]\ny_train = train[y_col].astype(float)\n\nX_test  = test[num_cols + cat_cols]\ny_test  = test[y_col].astype(float)\n\n# Pipeline: impute + scale numeric, OHE categorical\npre = ColumnTransformer(\n    transformers=[\n        (\"num\", Pipeline([\n            (\"imp\", SimpleImputer(strategy=\"median\")),\n            (\"scaler\", StandardScaler())\n        ]), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    ],\n    remainder=\"drop\",\n    sparse_threshold=0.3\n)\n\nmodel = Ridge(alpha=1.0, random_state=0)\n\npipe = Pipeline([(\"pre\", pre), (\"model\", model)])\npipe.fit(X_train, y_train)\n\ny_pred = pipe.predict(X_test)\n\n# Build prediction rows (match table columns dynamically)\npred = test[id_cols].copy()\npred[\"MODEL_RUN_ID\"] = ridge_mrid\npred[\"Y_TRUE\"] = y_test.values\npred[\"Y_PRED\"] = y_pred\npred[\"BUILT_AT\"] = np.datetime64(\"now\")\n\n# Align to actual prediction table columns\npred_cols = session.sql(\"\"\"\nselect column_name\nfrom DB_BI_P_SANDBOX.INFORMATION_SCHEMA.COLUMNS\nwhere table_schema='SANDBOX'\n  and table_name='FORECAST_MODEL_BACKTEST_PREDICTIONS'\norder by ordinal_position\n\"\"\").to_pandas()[\"COLUMN_NAME\"].tolist()\npred_cols_set = set(pred_cols)\n\n# keep only columns that exist in the table (case-sensitive to Snowflake output)\n# our pandas cols are uppercase already; if not, upper them\npred.columns = [c.upper() for c in pred.columns]\npred = pred[[c for c in pred.columns if c in pred_cols_set]]\n\n# Overwrite Ridge rows for these anchors (rerunnable)\nsession.sql(f\"\"\"\ndelete from DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\nwhere model_run_id = '{ridge_mrid}'\n  and anchor_month_seq in ({\",\".join([str(x) for x in EVAL_ANCHORS])})\n\"\"\").collect()\n\nsession.create_dataframe(pred).write.mode(\"append\").save_as_table(\n    \"DB_BI_P_SANDBOX.SANDBOX.FORECAST_MODEL_BACKTEST_PREDICTIONS\"\n)\n\nprint(\"Ridge predictions overwritten for anchors:\", EVAL_ANCHORS)\n",
   "execution_count": null
  }
 ]
}